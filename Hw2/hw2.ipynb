{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from lxml import etree\n",
    "import time\n",
    "\n",
    "# url = 'https://tain.tw/stats?type=2'\n",
    "url = 'https://tain.tw/'\n",
    "web = rq.get(url)                        # 取得網頁內容\n",
    "soup = soup(web.text, \"html.parser\")  # 轉換成標籤樹\n",
    "\n",
    "driver = webdriver.Chrome()    # 指向 chromedriver 的位置\n",
    "driver.get(url)   \n",
    "\n",
    "data_link = driver.find_element(By.XPATH, \"//a[@href='https://tain.tw/stats?type=2']\")\n",
    "\n",
    "# Click on the \"數據\" link to go to that section\n",
    "data_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_name():\n",
    "    data_column_name = []\n",
    "    sp = soup(driver.page_source, 'html.parser')\n",
    "    th_tags = sp.find('tr').find_all('th')\n",
    "    for th_tag in th_tags:\n",
    "        data_column_name.append(th_tag.text)\n",
    "    data_column_name = data_column_name[1:30]\n",
    "    return data_column_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    排名      勝率    直板勝率    橫板勝率    右手勝率    左手勝率    男子勝率    女子勝率     穩定率  \\\n",
      "0    1   66.67  100.00   62.50   75.00    0.00   66.67       -   66.67   \n",
      "1    2  100.00       -  100.00  100.00  100.00  100.00  100.00       -   \n",
      "2    3  100.00       -  100.00  100.00       -  100.00  100.00  100.00   \n",
      "3    4  100.00       -  100.00  100.00  100.00  100.00       -  100.00   \n",
      "4    5   88.00   85.71   88.37   90.00   80.00   87.50  100.00   91.30   \n",
      "5    6   85.71       -   85.71   85.71       -   83.33  100.00   85.71   \n",
      "6    7   79.10   72.73   81.25   81.03   71.43   79.03  100.00   94.44   \n",
      "7    8   80.95  100.00   80.00   88.24   50.00   78.95  100.00   75.00   \n",
      "8    9   96.55  100.00   95.83   95.45  100.00   95.83  100.00   96.43   \n",
      "9   10       -       -       -       -       -       -       -       -   \n",
      "10  11   90.91       -   90.91   90.00  100.00   88.89  100.00   95.00   \n",
      "11  12  100.00  100.00  100.00  100.00  100.00  100.00       -  100.00   \n",
      "12  13   83.33  100.00   81.82   77.78  100.00   83.33       -   83.33   \n",
      "13  14   93.65  100.00   93.22   96.30   77.78   92.98  100.00  100.00   \n",
      "14  15   75.00  100.00   71.43   73.33  100.00   75.00       -   80.00   \n",
      "15  16   70.59  100.00   66.67   78.57   33.33   66.67  100.00  100.00   \n",
      "16  17   94.12  100.00   93.75   93.75  100.00   92.86  100.00   94.12   \n",
      "17  18  100.00       -  100.00  100.00  100.00  100.00       -  100.00   \n",
      "18  19   85.71       -   85.71   85.71       -   85.71       -       -   \n",
      "19  20   50.00       -   50.00   66.67    0.00   50.00       -   50.00   \n",
      "\n",
      "       爆發率    平面勝率    短顆勝率    中顆勝率    長顆勝率    NT勝率  \n",
      "0        -   50.00    0.00       -       -       -  \n",
      "1        -  100.00  100.00       -  100.00       -  \n",
      "2        -  100.00       -       -       -  100.00  \n",
      "3        -  100.00       -       -       -       -  \n",
      "4    50.00   55.56   66.67  100.00       -    0.00  \n",
      "5        -  100.00  100.00       -       -       -  \n",
      "6    60.71  100.00  100.00       -       -       -  \n",
      "7    75.00   75.00  100.00       -       -       -  \n",
      "8        -   87.50  100.00       -  100.00       -  \n",
      "9        -       -       -       -       -       -  \n",
      "10  100.00   81.82  100.00       -  100.00  100.00  \n",
      "11       -  100.00       -       -  100.00       -  \n",
      "12       -   50.00  100.00       -  100.00       -  \n",
      "13   92.16   73.33  100.00  100.00  100.00       -  \n",
      "14       -   70.00       -       -  100.00       -  \n",
      "15   83.33   44.44       -       -  100.00       -  \n",
      "16  100.00   87.50       -       -       -       -  \n",
      "17  100.00  100.00       -  100.00       -       -  \n",
      "18       -   83.33  100.00       -       -       -  \n",
      "19       -   33.33       -       -  100.00       -  \n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv \n",
    "\n",
    "\n",
    "# Initialize a Selenium web driver\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://tain.tw/stats?type=2'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load (you can adjust the sleep time)\n",
    "time.sleep(3)\n",
    "\n",
    "# Find the table using XPath\n",
    "table = driver.find_element(By.XPATH, \"//table[@class='table table-sm table-hover text-nowrap fs-caption']\")\n",
    "\n",
    "# Get the HTML content of the table\n",
    "table_html = table.get_attribute('outerHTML')\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup_table = soup(table_html, 'html.parser')\n",
    "\n",
    "# Find all table rows\n",
    "rows = soup_table.find_all('tr')\n",
    "\n",
    "# Create empty lists to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through the rows and extract data\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    columns = row.find_all('td')\n",
    "    row_data = [column.get_text(strip=True) for column in columns]\n",
    "    data.append(row_data)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data, columns=[ '排名', '勝率', '直板勝率', '橫板勝率', '右手勝率', '左手勝率', '男子勝率', '女子勝率', '穩定率', '爆發率', '平面勝率', '短顆勝率', '中顆勝率', '長顆勝率', 'NT勝率'])\n",
    "\n",
    "# Close the Selenium web driver\n",
    "driver.quit()\n",
    "\n",
    "# Display the extracted data in a DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        排名      勝率    直板勝率    橫板勝率    右手勝率    左手勝率    男子勝率    女子勝率     穩定率  \\\n",
      "0        1   66.67  100.00   62.50   75.00    0.00   66.67       -   66.67   \n",
      "1        2  100.00       -  100.00  100.00  100.00  100.00  100.00       -   \n",
      "2        3  100.00       -  100.00  100.00       -  100.00  100.00  100.00   \n",
      "3        4  100.00       -  100.00  100.00  100.00  100.00       -  100.00   \n",
      "4        5   88.00   85.71   88.37   90.00   80.00   87.50  100.00   91.30   \n",
      "...    ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "2875  2870    0.00       -    0.00    0.00    0.00    0.00       -       -   \n",
      "2876  2871    0.00       -    0.00    0.00    0.00    0.00    0.00       -   \n",
      "2877  2872    0.00       -    0.00    0.00    0.00    0.00    0.00       -   \n",
      "2878  2873    0.00       -    0.00    0.00       -    0.00       -       -   \n",
      "2879  2874    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "\n",
      "        爆發率    平面勝率    短顆勝率    中顆勝率    長顆勝率    NT勝率  \n",
      "0         -   50.00    0.00       -       -       -  \n",
      "1         -  100.00  100.00       -  100.00       -  \n",
      "2         -  100.00       -       -       -  100.00  \n",
      "3         -  100.00       -       -       -       -  \n",
      "4     50.00   55.56   66.67  100.00       -    0.00  \n",
      "...     ...     ...     ...     ...     ...     ...  \n",
      "2875   0.00    0.00       -    0.00       -       -  \n",
      "2876   0.00    0.00       -       -       -       -  \n",
      "2877   0.00    0.00       -    0.00       -       -  \n",
      "2878   0.00    0.00    0.00       -       -    0.00  \n",
      "2879   0.00   38.89    0.00       -       -       -  \n",
      "\n",
      "[2880 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Initialize a Selenium web driver\n",
    "driver = webdriver.Chrome()\n",
    "base_url = 'https://tain.tw/stats?type=2&points_page=143'\n",
    "driver.get(base_url)\n",
    "\n",
    "# Wait for the page to load (you can adjust the sleep time)\n",
    "time.sleep(3)\n",
    "\n",
    "# Create an empty list to store all the data\n",
    "all_data = []\n",
    "\n",
    "for i in range(0,1): \n",
    "    # Find the table using XPath\n",
    "    table = driver.find_element(By.XPATH, \"//table[@class='table table-sm table-hover text-nowrap fs-caption']\")\n",
    "\n",
    "    # Get the HTML content of the table\n",
    "    table_html = table.get_attribute('outerHTML')\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup_table = soup(table_html, 'html.parser')\n",
    "\n",
    "    # Find all table rows\n",
    "    rows = soup_table.find_all('tr')\n",
    "\n",
    "    # Create empty lists to store the data for the current page\n",
    "    data = []\n",
    "\n",
    "    # Iterate through the rows and extract data\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        columns = row.find_all('td')\n",
    "        row_data = [column.get_text(strip=True) for column in columns]\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Append the data for the current page to the list of all data\n",
    "    all_data.extend(data)\n",
    "\n",
    "    driver.maximize_window()\n",
    "    # Find the \"Next\" link using the specified criteria\n",
    "    #\n",
    "     # Find the URL of the \"Next\" page, if available\n",
    "    # next_page_element = driver.find_element(By.XPATH, \"//li[@class='page-item' and not(@aria-disabled='true')]/a[@class='page-link']\")\n",
    "    next_page_element = driver.find_element(By.XPATH, \"//li[@class='page-item' and not(@aria-disabled='true')]/a[@class='page-link' and contains(@aria-label, 'Next »')]\")\n",
    "    next_page_url = next_page_element.get_attribute('href')\n",
    "    \n",
    "    if next_page_url:\n",
    "        # Navigate to the next page\n",
    "        driver.get(next_page_url)\n",
    "    else:\n",
    "        break  # No more pages to scrape\n",
    "    # next_page_element = driver.find_element(By.CSS_SELECTOR, 'a.page-link[rel=\"next\"]')\n",
    "    \n",
    "    # try:\n",
    "    #     # Find the \"Next\" link using the specified criteria\n",
    "    #     next_page_element = driver.find_element(By.CSS_SELECTOR, 'a.page-link[rel=\"next\"]')\n",
    "    #     # Scroll to the element\n",
    "    #     driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_element)\n",
    "    #     time.sleep(1)  # Allow some time for scrolling to complete\n",
    "    #     next_page_element.send_keys(Keys.ENTER)\n",
    "    # except NoSuchElementException:\n",
    "    #     break  # No more pages to scrape\n",
    "\n",
    "# Create a DataFrame from all the extracted data\n",
    "df = pd.DataFrame(all_data, columns=['排名', '勝率', '直板勝率', '橫板勝率', '右手勝率', '左手勝率', '男子勝率', '女子勝率', '穩定率', '爆發率', '平面勝率', '短顆勝率', '中顆勝率', '長顆勝率', 'NT勝率'])\n",
    "\n",
    "# Close the Selenium web driver\n",
    "driver.quit()\n",
    "\n",
    "with open('result.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(all_data)\n",
    "\n",
    "    \n",
    "# Display the extracted data in a DataFrame\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pos   球員    排名     勝率    直板勝率   橫板勝率   右手勝率    左手勝率   男子勝率   女子勝率    穩定率  \\\n",
      "0   2841  李岳哲  2835  20.00       -  20.00  20.00       -  25.00   0.00      -   \n",
      "1   2842  廖亦鈞  2836   0.00       -   0.00   0.00    0.00   0.00      -   0.00   \n",
      "2   2843  林愷樂  2837  40.00       -  40.00  50.00    0.00  40.00      -  50.00   \n",
      "3   2844  康耀翔  2838  12.50    0.00  14.29  12.50       -  16.67   0.00  20.00   \n",
      "4   2845  方嘉圖  2839   0.00    0.00   0.00   0.00    0.00   0.00   0.00   0.00   \n",
      "5   2846  林璟翔  2840   0.00    0.00   0.00   0.00    0.00   0.00   0.00      -   \n",
      "6   2847  林欣蓉  2841   0.00       -   0.00   0.00    0.00   0.00      -      -   \n",
      "7   2848  許家豪  2842   0.00       -   0.00   0.00    0.00   0.00   0.00      -   \n",
      "8   2849  許家祥  2843   0.00       -   0.00   0.00       -   0.00   0.00      -   \n",
      "9   2850  邱苡瑄  2844  45.45  100.00  40.00  50.00   33.33  50.00  40.00  62.50   \n",
      "10  2851  賴穎恩  2845   9.30   20.00   7.89  10.00    0.00   6.25  18.18  12.50   \n",
      "11  2852  李宣慧  2846   0.00       -   0.00   0.00       -   0.00      -   0.00   \n",
      "12  2853  李育榮  2847  38.89    0.00  43.75  41.18    0.00  38.46  40.00      -   \n",
      "13  2854  周誠致  2848   0.00    0.00   0.00   0.00       -   0.00   0.00   0.00   \n",
      "14  2855  林佑叡  2849   0.00    0.00   0.00   0.00    0.00   0.00      -      -   \n",
      "15  2856  王唯全  2850  25.00    0.00  28.57  25.00       -  25.00      -      -   \n",
      "16  2857  蔡孟錦  2851   0.00       -   0.00   0.00    0.00   0.00   0.00   0.00   \n",
      "17  2858  彭惟惟  2852  25.00    0.00  30.00  25.00       -  25.00  25.00   0.00   \n",
      "18  2859  蔡宜達  2853  15.38       -  15.38  15.38       -  16.67   0.00      -   \n",
      "19  2860  曾詣喬  2854  25.00  100.00   0.00   0.00  100.00  25.00      -      -   \n",
      "\n",
      "      爆發率   平面勝率   短顆勝率  中顆勝率  長顆勝率  NT勝率  \n",
      "0   20.00  20.00      -     -     -     -  \n",
      "1    0.00   0.00      -     -     -     -  \n",
      "2   33.33  40.00      -     -     -     -  \n",
      "3    0.00  41.67      -     -     -     -  \n",
      "4    0.00  26.32   0.00     -     -     -  \n",
      "5    0.00   0.00      -     -     -  0.00  \n",
      "6    0.00   0.00      -     -     -     -  \n",
      "7    0.00   0.00   0.00     -     -     -  \n",
      "8    0.00   0.00      -  0.00     -     -  \n",
      "9   33.33  50.00      -  0.00     -     -  \n",
      "10   9.09  47.69  50.00  0.00  0.00     -  \n",
      "11   0.00   0.00      -     -     -     -  \n",
      "12      -  52.38      -  0.00     -     -  \n",
      "13   0.00  36.36      -     -     -     -  \n",
      "14   0.00   0.00      -     -     -     -  \n",
      "15  25.00  44.44   0.00     -     -     -  \n",
      "16   0.00   0.00      -  0.00     -     -  \n",
      "17  30.00  50.00      -     -     -     -  \n",
      "18  15.38  47.06   0.00     -  0.00     -  \n",
      "19  25.00   0.00  50.00     -     -     -  \n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Initialize a Selenium web driver\n",
    "driver = webdriver.Chrome()\n",
    "base_url = 'https://tain.tw/stats?type=2&points_page=1'\n",
    "driver.get(base_url)\n",
    "\n",
    "# Wait for the page to load (you can adjust the sleep time)\n",
    "time.sleep(3)\n",
    "\n",
    "# Create an empty list to store all the data\n",
    "all_data = []\n",
    "\n",
    "# Define the desired column names\n",
    "column_names = ['Pos', '球員', '排名', '勝率', '直板勝率', '橫板勝率', '右手勝率', '左手勝率', '男子勝率', '女子勝率', '穩定率', '爆發率', '平面勝率', '短顆勝率', '中顆勝率', '長顆勝率', 'NT勝率']\n",
    "\n",
    "# Add the column names as the first row\n",
    "all_data.append(column_names)\n",
    "\n",
    "for i in range(0, 144):\n",
    "    # Find the table using XPath\n",
    "    table = driver.find_element(By.XPATH, \"//table[@class='table table-sm table-hover text-nowrap fs-caption']\")\n",
    "\n",
    "    # Get the HTML content of the table\n",
    "    table_html = table.get_attribute('outerHTML')\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup_table = soup(table_html, 'html.parser')\n",
    "\n",
    "    # Find all table rows\n",
    "    rows = soup_table.find_all('tr')\n",
    "\n",
    "    # Create empty lists to store the data for the current page\n",
    "    data = []\n",
    "\n",
    "    # Iterate through the rows and extract data\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        columns = row.find_all(['th', 'td'])\n",
    "        row_data = [column.get_text(strip=True) for column in columns]\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Append the data for the current page to the list of all data\n",
    "    all_data.extend(data)\n",
    "\n",
    "    driver.maximize_window()\n",
    "    # Find the \"Next\" link using the specified criteria\n",
    "    #\n",
    "    # Find the URL of the \"Next\" page, if available\n",
    "    next_page_element = driver.find_element(By.XPATH, \"//li[@class='page-item' and not(@aria-disabled='true')]/a[@class='page-link' and contains(@aria-label, 'Next »')]\")\n",
    "    next_page_url = next_page_element.get_attribute('href')\n",
    "\n",
    "    if next_page_url:\n",
    "        # Navigate to the next page\n",
    "        driver.get(next_page_url)\n",
    "    else:\n",
    "        break  # No more pages to scrape\n",
    "\n",
    "# Create a DataFrame from all the extracted data\n",
    "df = pd.DataFrame(all_data[1:], columns=all_data[0])\n",
    "\n",
    "# Close the Selenium web driver\n",
    "driver.quit()\n",
    "\n",
    "with open('result.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(all_data)\n",
    "\n",
    "# Display the extracted data in a DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataVisualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
